{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A little 'get started with the LIMS / PostgreSQL / Python connection' notebook following up on the Software Carpentry Workshop.\n",
    "####  Agata Budzillo, 4/12/2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The three functions below will allow you to open a connection with the LIMS database, send a query and collect the results, and then (importantly) close the connection so LIMS doesn't get hung up. I wouldn't worry too much about the details of these at the moment, but I'm happy to answer questions if they arise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def _connect(user=\"limsreader\", host=\"limsdb2\", database=\"lims2\", password=\"limsro\", port=5432):\n",
    "    import pg8000\n",
    "    conn = pg8000.connect(user=user, host=host, database=database, password=password, port=port)\n",
    "    return conn, conn.cursor()\n",
    "\n",
    "def _select(cursor, query):\n",
    "    cursor.execute(query)\n",
    "    columns = [ d[0] for d in cursor.description ]\n",
    "    return [ dict(zip(columns, c)) for c in cursor.fetchall() ]\n",
    "\n",
    "def limsquery(query, user=\"limsreader\", host=\"limsdb2\", database=\"lims2\", password=\"limsro\", port=5432):\n",
    "    \"\"\"A function that takes a string containing a SQL query, connects to the LIMS database and outputs the result.\"\"\"\n",
    "    conn, cursor = _connect(user, host, database, password, port)\n",
    "    try:\n",
    "        results = _select(cursor, query)\n",
    "    finally:\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIMS has a looooot of tables. One of the most useful ones to get acquainted with is 'specimens'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_bigquery = \"SELECT * FROM specimens\"\n",
    "my_bigresult = limsquery(my_bigquery)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Well now that took an awfully long time. From now on when we run our test queries, let's limit the number of results we get back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_query = \"SELECT * FROM specimens LIMIT 10\"\n",
    "my_result = limsquery(my_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What in the world is in my result? Let's ask Python what it thinks..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n",
      "Length of myresult: 10\n"
     ]
    }
   ],
   "source": [
    "print type(my_result)\n",
    "print \"Length of myresult:\", len(my_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It's a list of the same length as the # of results to which we limited our query.  What's the first thing in the list?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cell_depth': None, 'ephys_roi_result_id': None, 'parent_y_coord': 0, 'reference_space_id': None, 'updated_at': datetime.datetime(2016, 12, 16, 4, 54, 44, 477335), 'cell_label': None, 'preparation_method_id': None, 'parent_x_coord': 2, 'location_id': None, 'id': 556516441, 'cortex_layer_id': None, 'plane_of_section_id': 11, 'frozen_at': None, 'flipped_specimen_id': 561557765, 'data': None, 'rna_integrity_number': None, 'histology_well_name': None, 'created_by': None, 'priority': None, 'parent_id': 556516212, 'project_id': 305094322, 'alignment3d_id': None, 'carousel_well_name': u'T301_122_161107_01_12', 'patched_cell_container': None, 'updated_by': None, 'cell_prep_id': None, 'biophysical_model_state': u'review_required', 'barcode': u'0556516441', 'storage_directory': None, 'tissue_ph': None, 'specimen_preparation_method_id': None, 'donor_id': 555257198, 'ephys_neural_tissue_plan_id': 555257244, 'structure_id': None, 'parent_z_coord': 0, 'facs_well_id': None, 'name': u'Ndnf-IRES2-dgCre;Ai14-280612.06.02', 'normalization_group_id': None, 'postmortem_interval_id': None, 'specimen_set_id': None, 'created_at': datetime.datetime(2016, 11, 7, 16, 3, 11, 459275), 'tissue_processing_id': 555257241, 'ephys_cell_plan_id': None, 'hemisphere_id': None, 'cell_reporter_id': None, 'task_flow_id': None, 'external_specimen_name': None}\n"
     ]
    }
   ],
   "source": [
    "first_element = myresult[0]\n",
    "print first_element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eew, what is that!?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print type(first_element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aha, Python says it's a dictionary! This is an incredibly useful and efficient data structure that we didn't really discuss in the Software Carpentry Workshop. A dictionary is made up of key:value pairs. Just to make that clear, below I'm looping across every key in the dictionary that is the first element of my results list, printing the name of the key and the value that the key is associated with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell_depth : None\n",
      "ephys_roi_result_id : None\n",
      "parent_y_coord : 0\n",
      "reference_space_id : None\n",
      "updated_at : 2016-12-16 04:54:44.477335\n",
      "cell_label : None\n",
      "preparation_method_id : None\n",
      "parent_x_coord : 2\n",
      "location_id : None\n",
      "id : 556516441\n",
      "cortex_layer_id : None\n",
      "plane_of_section_id : 11\n",
      "frozen_at : None\n",
      "flipped_specimen_id : 561557765\n",
      "data : None\n",
      "rna_integrity_number : None\n",
      "histology_well_name : None\n",
      "created_by : None\n",
      "priority : None\n",
      "parent_id : 556516212\n",
      "project_id : 305094322\n",
      "alignment3d_id : None\n",
      "carousel_well_name : T301_122_161107_01_12\n",
      "patched_cell_container : None\n",
      "updated_by : None\n",
      "cell_prep_id : None\n",
      "biophysical_model_state : review_required\n",
      "barcode : 0556516441\n",
      "storage_directory : None\n",
      "tissue_ph : None\n",
      "specimen_preparation_method_id : None\n",
      "donor_id : 555257198\n",
      "ephys_neural_tissue_plan_id : 555257244\n",
      "structure_id : None\n",
      "parent_z_coord : 0\n",
      "facs_well_id : None\n",
      "name : Ndnf-IRES2-dgCre;Ai14-280612.06.02\n",
      "normalization_group_id : None\n",
      "postmortem_interval_id : None\n",
      "specimen_set_id : None\n",
      "created_at : 2016-11-07 16:03:11.459275\n",
      "tissue_processing_id : 555257241\n",
      "ephys_cell_plan_id : None\n",
      "hemisphere_id : None\n",
      "cell_reporter_id : None\n",
      "task_flow_id : None\n",
      "external_specimen_name : None\n"
     ]
    }
   ],
   "source": [
    "my_dict = first_element\n",
    "for my_key in my_dict.keys():\n",
    "    my_val = my_dict[my_key]\n",
    "    print my_key, \":\", my_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1: Your turn - return the specimen names for all the query results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ndnf-IRES2-dgCre;Ai14-280612.06.02\n",
      "Ai14-Homo-280711.10\n",
      "Sst-IRES-Cre;Ai140;Pvalb-2A-FlpO;Ai65F-303812\n",
      "Htr3a-Cre_NO152;Ai14-288785\n",
      "H16.03.002.01.06.02\n",
      "Slc17a6-IRES-Cre-125964\n",
      "Sim1-Cre_KJ18;Ai14-264358.16\n",
      "Sim1-Cre_KJ18;Ai14-264358.10\n",
      "Cux2-CreERT2-124835\n",
      "Sim1-Cre_KJ18;Ai14-264358.11\n"
     ]
    }
   ],
   "source": [
    "# A1:\n",
    "for result in my_result:\n",
    "    print result[\"name\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionaries are cool, but since this is tabular data, it might make sense to load it into a Pandas Dataframe, so it's all nice and pretty. Here's one way of doing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lims_dataframe(query):\n",
    "    '''Return a dataframe with lims query'''\n",
    "    import pandas as pd\n",
    "    result = limsquery(query)\n",
    "    try:\n",
    "        data_df = pd.DataFrame(data=result, columns=result[0].keys())\n",
    "    except IndexError:\n",
    "        print \"Could not find results for your query.\"\n",
    "        data_df = pd.DataFrame()\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_depth</th>\n",
       "      <th>ephys_roi_result_id</th>\n",
       "      <th>parent_y_coord</th>\n",
       "      <th>reference_space_id</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>cell_label</th>\n",
       "      <th>preparation_method_id</th>\n",
       "      <th>parent_x_coord</th>\n",
       "      <th>location_id</th>\n",
       "      <th>id</th>\n",
       "      <th>...</th>\n",
       "      <th>normalization_group_id</th>\n",
       "      <th>postmortem_interval_id</th>\n",
       "      <th>specimen_set_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>tissue_processing_id</th>\n",
       "      <th>ephys_cell_plan_id</th>\n",
       "      <th>hemisphere_id</th>\n",
       "      <th>cell_reporter_id</th>\n",
       "      <th>task_flow_id</th>\n",
       "      <th>external_specimen_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2016-12-16 04:54:44.477335</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>556516441</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2016-11-07 16:03:11.459275</td>\n",
       "      <td>555257241.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2016-12-16 04:54:44.502455</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>557340893</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2016-11-10 18:44:08.892340</td>\n",
       "      <td>553464045.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2017-03-01 16:37:56.349162</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>571099320</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2017-02-24 16:19:14.340373</td>\n",
       "      <td>571099382.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2016-12-20 15:59:41.497432</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>561463630</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2016-12-14 17:16:20.787949</td>\n",
       "      <td>561463640.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79.5</td>\n",
       "      <td>520465696.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2016-12-16 04:20:18.220136</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>520465880</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2016-05-25 01:53:53.036673</td>\n",
       "      <td>NaN</td>\n",
       "      <td>497017362.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cell_depth  ephys_roi_result_id  parent_y_coord reference_space_id  \\\n",
       "0         NaN                  NaN             0.0               None   \n",
       "1         NaN                  NaN             0.0               None   \n",
       "2         NaN                  NaN             NaN               None   \n",
       "3         NaN                  NaN             NaN               None   \n",
       "4        79.5          520465696.0             0.0               None   \n",
       "\n",
       "                  updated_at cell_label preparation_method_id  parent_x_coord  \\\n",
       "0 2016-12-16 04:54:44.477335       None                  None             2.0   \n",
       "1 2016-12-16 04:54:44.502455       None                  None             0.0   \n",
       "2 2017-03-01 16:37:56.349162       None                  None             NaN   \n",
       "3 2016-12-20 15:59:41.497432       None                  None             NaN   \n",
       "4 2016-12-16 04:20:18.220136       None                  None             0.0   \n",
       "\n",
       "  location_id         id           ...           normalization_group_id  \\\n",
       "0        None  556516441           ...                             None   \n",
       "1        None  557340893           ...                             None   \n",
       "2        None  571099320           ...                             None   \n",
       "3        None  561463630           ...                             None   \n",
       "4        None  520465880           ...                             None   \n",
       "\n",
       "   postmortem_interval_id specimen_set_id                 created_at  \\\n",
       "0                    None            None 2016-11-07 16:03:11.459275   \n",
       "1                    None            None 2016-11-10 18:44:08.892340   \n",
       "2                    None            None 2017-02-24 16:19:14.340373   \n",
       "3                    None            None 2016-12-14 17:16:20.787949   \n",
       "4                    None            None 2016-05-25 01:53:53.036673   \n",
       "\n",
       "  tissue_processing_id ephys_cell_plan_id hemisphere_id cell_reporter_id  \\\n",
       "0          555257241.0                NaN          None             None   \n",
       "1          553464045.0                NaN          None             None   \n",
       "2          571099382.0                NaN          None             None   \n",
       "3          561463640.0                NaN          None             None   \n",
       "4                  NaN        497017362.0          None             None   \n",
       "\n",
       "  task_flow_id  external_specimen_name  \n",
       "0         None                    None  \n",
       "1         None                    None  \n",
       "2         None                    None  \n",
       "3         None                    None  \n",
       "4         None                    None  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df = get_lims_dataframe(myquery)\n",
    "my_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OK  well I don't know about you, but I'm annoyed by all these useless columns here. Who cares about tissue_processing_id!? Just kidding... We can limit what fields we take back from LIMS. I showed you the first way (with the wildcard *), though, because sometimes it can be tricky to know what the available fieldnames in a given table are ahead of time. For example, they often do not match up to the names displayed in the LIMS tables you may be accustomed to exploring through the web interface. Let's say we just want the specimen name, the ephys roi id and the specimen id...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ephys_roi_result_id</th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Ndnf-IRES2-dgCre;Ai14-280612.06.02</td>\n",
       "      <td>556516441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Ai14-Homo-280711.10</td>\n",
       "      <td>557340893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Sst-IRES-Cre;Ai140;Pvalb-2A-FlpO;Ai65F-303812</td>\n",
       "      <td>571099320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Htr3a-Cre_NO152;Ai14-288785</td>\n",
       "      <td>561463630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>520465696.0</td>\n",
       "      <td>H16.03.002.01.06.02</td>\n",
       "      <td>520465880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ephys_roi_result_id                                           name  \\\n",
       "0                  NaN             Ndnf-IRES2-dgCre;Ai14-280612.06.02   \n",
       "1                  NaN                            Ai14-Homo-280711.10   \n",
       "2                  NaN  Sst-IRES-Cre;Ai140;Pvalb-2A-FlpO;Ai65F-303812   \n",
       "3                  NaN                    Htr3a-Cre_NO152;Ai14-288785   \n",
       "4          520465696.0                            H16.03.002.01.06.02   \n",
       "\n",
       "          id  \n",
       "0  556516441  \n",
       "1  557340893  \n",
       "2  571099320  \n",
       "3  561463630  \n",
       "4  520465880  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_refinedquery = \"SELECT name, id, ephys_roi_result_id FROM specimens LIMIT 5\"\n",
    "refined_df = get_lims_dataframe(my_refinedquery)\n",
    "myrefined_dataframe.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sweet. Now, are these all electrophysiology specimens? Why do some of them have odd names and no roi id? It's because specimens in LIMS are all specimens, not just electrophysiology specimens. So how do we narrow down to ephys specimens? That will require a table merge. It's kind of a weird one, though as we will have to merge the table with itself.  Whhaaaat? Yeah. So before we do that, let's work on a more 'traditional' merge.  Let's work with a couple of new tables, ephys_roi_results and users to find out which recordings a given rig user served as stage 1 reviewer for...\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workflow_state</th>\n",
       "      <th>id</th>\n",
       "      <th>recording_date</th>\n",
       "      <th>stage1_reviewer_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>auto_failed</td>\n",
       "      <td>539646734</td>\n",
       "      <td>2016-08-17 10:18:51</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qc</td>\n",
       "      <td>306486658</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qc</td>\n",
       "      <td>305384219</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>auto_failed</td>\n",
       "      <td>539011260</td>\n",
       "      <td>2016-08-12 11:04:58</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qc</td>\n",
       "      <td>306007448</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  workflow_state         id      recording_date  stage1_reviewer_id\n",
       "0    auto_failed  539646734 2016-08-17 10:18:51                 NaN\n",
       "1             qc  306486658                 NaT                 NaN\n",
       "2             qc  305384219                 NaT                 NaN\n",
       "3    auto_failed  539011260 2016-08-12 11:04:58                 NaN\n",
       "4             qc  306007448                 NaT                 NaN"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_query = \"SELECT id, recording_date, stage1_reviewer_id, workflow_state FROM ephys_roi_results\"\n",
    "err_df = get_lims_dataframe(new_query)\n",
    "err_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hmm seeing a lot of NaNs in stage1_reviewer_id? Remember that we only implemented this into LIMS this past fall. Can you figure out how to limit the results to only 2017? The syntax of the wrapper for PostGreSQL in Python is a little funny. Hint: the date may need to be passed in quotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workflow_state</th>\n",
       "      <th>id</th>\n",
       "      <th>recording_date</th>\n",
       "      <th>stage1_reviewer_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>auto_failed</td>\n",
       "      <td>569387813</td>\n",
       "      <td>2017-02-08 10:52:32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>auto_failed</td>\n",
       "      <td>580133753</td>\n",
       "      <td>2017-04-07 10:32:16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>manual_passed</td>\n",
       "      <td>570428511</td>\n",
       "      <td>2017-02-21 09:44:42</td>\n",
       "      <td>305127608.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>manual_passed</td>\n",
       "      <td>571255031</td>\n",
       "      <td>2017-02-27 11:12:23</td>\n",
       "      <td>525757437.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>auto_failed</td>\n",
       "      <td>575894497</td>\n",
       "      <td>2017-03-22 09:30:05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  workflow_state         id      recording_date  stage1_reviewer_id\n",
       "0    auto_failed  569387813 2017-02-08 10:52:32                 NaN\n",
       "1    auto_failed  580133753 2017-04-07 10:32:16                 NaN\n",
       "2  manual_passed  570428511 2017-02-21 09:44:42         305127608.0\n",
       "3  manual_passed  571255031 2017-02-27 11:12:23         525757437.0\n",
       "4    auto_failed  575894497 2017-03-22 09:30:05                 NaN"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_query = \"SELECT id, recording_date, stage1_reviewer_id, workflow_state \\\n",
    "FROM ephys_roi_results WHERE recording_date > '2017-01-01'\"\n",
    "err_df = get_lims_dataframe(new_query)\n",
    "err_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nice. There are still NaNs, but only where the workflow state was dodgy. So there is another table that could come in handy now, called users. What's in this table? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users_query = \"SELECT id, login FROM users\"\n",
    "users_df = get_lims_dataframe(users_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's find your user id given your Allen login."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>login</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>agatab</td>\n",
       "      <td>527452252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    login         id\n",
       "0  agatab  527452252"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df = get_lims_dataframe(\"SELECT id, login FROM users WHERE login = 'agatab'\")\n",
    "users_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sweet! So all we need to do now is JOIN the users table on our ephys results table to figure out which samples you were a stage 1 reviewer for... JOINs can be a little complicated, so I recommend you tread carefully. Come ask if you need help or if your results do not make sense. The syntax is the following. You'll want to list all of the field names from all of the tables you want at the beginning in the SELECT statement, then your FROM statement and then any number of JOIN (table name) ON (column name). The filters (ie WHERE, LIMIT, ORDER BY) always go at the end. By default JOIN will be an INNER JOIN (think the overlapping section in a Venn diagram). This is also a good time to bring up aliasing. Aliasing is IMO always a good idea. Imagine you write the following: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "(u'ERROR', u'42702', u'column reference \"id\" is ambiguous', u'132', u'parse_relation.c', u'654', u'colNameToVar', u'', u'')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-201-626fe91a5d2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mjoin_query\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"SELECT id, recording_date, stage1_reviewer_id, workflow_state, id, login FROM ephys_roi_results JOIN users ON stage1_reviewer_id = id WHERE recording_date > '2017-01-01'\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mjoin_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_lims_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin_query\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-181-96df63741ce0>\u001b[0m in \u001b[0;36mget_lims_dataframe\u001b[1;34m(query)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;34m'''Return a dataframe with lims query'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlimsquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mdata_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-170-812ad8475914>\u001b[0m in \u001b[0;36mlimsquery\u001b[1;34m(query, user, host, database, password, port)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcursor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_connect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatabase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpassword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_select\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcursor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-170-812ad8475914>\u001b[0m in \u001b[0;36m_select\u001b[1;34m(cursor, query)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_select\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcursor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescription\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\pg8000\\core.pyc\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, operation, args, stream)\u001b[0m\n\u001b[0;32m    904\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_transaction\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautocommit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    905\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"begin transaction\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 906\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    907\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\pg8000\\core.pyc\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, cursor, operation, vals)\u001b[0m\n\u001b[0;32m   1938\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mOperationalError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1940\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_messages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcursor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1941\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1942\u001b[0m             \u001b[1;31m# We've got row_desc that allows us to identify what we're\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\pg8000\\core.pyc\u001b[0m in \u001b[0;36mhandle_messages\u001b[1;34m(self, cursor)\u001b[0m\n\u001b[0;32m   2086\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2087\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2088\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2089\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2090\u001b[0m     \u001b[1;31m# Byte1('C') - Identifies the message as a close command.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mProgrammingError\u001b[0m: (u'ERROR', u'42702', u'column reference \"id\" is ambiguous', u'132', u'parse_relation.c', u'654', u'colNameToVar', u'', u'')"
     ]
    }
   ],
   "source": [
    "join_query = \"SELECT id, recording_date, stage1_reviewer_id, workflow_state, id, login \\\n",
    "FROM ephys_roi_results \\\n",
    "JOIN users ON stage1_reviewer_id = id \\\n",
    "WHERE recording_date > '2017-01-01'\"\n",
    "join_df = get_lims_dataframe(join_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Well, that was an epic fail. Both ephys_roi_results and users have an id column so Python is not happy. In fact if you look at the bottom of the traceback the error message is : 'column reference \"id\" is ambiguous'. The proper way to do this is to explicitly call the field name from the table, like so:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>login</th>\n",
       "      <th>workflow_state</th>\n",
       "      <th>id</th>\n",
       "      <th>recording_date</th>\n",
       "      <th>stage1_reviewer_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>samj</td>\n",
       "      <td>manual_passed</td>\n",
       "      <td>525757437</td>\n",
       "      <td>2017-01-06 09:07:31</td>\n",
       "      <td>525757437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>samj</td>\n",
       "      <td>manual_failed</td>\n",
       "      <td>525757437</td>\n",
       "      <td>2017-01-04 15:42:32</td>\n",
       "      <td>525757437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>samj</td>\n",
       "      <td>manual_passed</td>\n",
       "      <td>525757437</td>\n",
       "      <td>2017-01-05 14:39:22</td>\n",
       "      <td>525757437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>samj</td>\n",
       "      <td>manual_passed</td>\n",
       "      <td>525757437</td>\n",
       "      <td>2017-01-05 13:28:19</td>\n",
       "      <td>525757437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>samj</td>\n",
       "      <td>manual_passed</td>\n",
       "      <td>525757437</td>\n",
       "      <td>2017-01-04 10:17:49</td>\n",
       "      <td>525757437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    login workflow_state         id      recording_date  stage1_reviewer_id\n",
       "705  samj  manual_passed  525757437 2017-01-06 09:07:31           525757437\n",
       "706  samj  manual_failed  525757437 2017-01-04 15:42:32           525757437\n",
       "707  samj  manual_passed  525757437 2017-01-05 14:39:22           525757437\n",
       "708  samj  manual_passed  525757437 2017-01-05 13:28:19           525757437\n",
       "709  samj  manual_passed  525757437 2017-01-04 10:17:49           525757437"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_query = \"SELECT ephys_roi_results.id, ephys_roi_results.recording_date, ephys_roi_results.stage1_reviewer_id, \\\n",
    "ephys_roi_results.workflow_state, users.id, users.login \\\n",
    "FROM ephys_roi_results \\\n",
    "JOIN users ON ephys_roi_results.stage1_reviewer_id = users.id \\\n",
    "WHERE recording_date > '2017-01-01'\"\n",
    "join_df = get_lims_dataframe(join_query)\n",
    "join_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That works! But it's super clunky. That's where aliases comes in handy. \"'Alias' was a show about a spy....\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>login</th>\n",
       "      <th>workflow_state</th>\n",
       "      <th>id</th>\n",
       "      <th>recording_date</th>\n",
       "      <th>stage1_reviewer_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>samj</td>\n",
       "      <td>manual_passed</td>\n",
       "      <td>525757437</td>\n",
       "      <td>2017-01-06 09:07:31</td>\n",
       "      <td>525757437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>samj</td>\n",
       "      <td>manual_failed</td>\n",
       "      <td>525757437</td>\n",
       "      <td>2017-01-04 15:42:32</td>\n",
       "      <td>525757437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>samj</td>\n",
       "      <td>manual_passed</td>\n",
       "      <td>525757437</td>\n",
       "      <td>2017-01-05 14:39:22</td>\n",
       "      <td>525757437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>samj</td>\n",
       "      <td>manual_passed</td>\n",
       "      <td>525757437</td>\n",
       "      <td>2017-01-05 13:28:19</td>\n",
       "      <td>525757437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>samj</td>\n",
       "      <td>manual_passed</td>\n",
       "      <td>525757437</td>\n",
       "      <td>2017-01-04 10:17:49</td>\n",
       "      <td>525757437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    login workflow_state         id      recording_date  stage1_reviewer_id\n",
       "705  samj  manual_passed  525757437 2017-01-06 09:07:31           525757437\n",
       "706  samj  manual_failed  525757437 2017-01-04 15:42:32           525757437\n",
       "707  samj  manual_passed  525757437 2017-01-05 14:39:22           525757437\n",
       "708  samj  manual_passed  525757437 2017-01-05 13:28:19           525757437\n",
       "709  samj  manual_passed  525757437 2017-01-04 10:17:49           525757437"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_query = \"SELECT err.id, err.recording_date, err.stage1_reviewer_id, \\\n",
    "err.workflow_state, users.id, users.login \\\n",
    "FROM ephys_roi_results err \\\n",
    "JOIN users ON err.stage1_reviewer_id = users.id \\\n",
    "WHERE recording_date > '2017-01-01'\"\n",
    "join_df = get_lims_dataframe(join_query)\n",
    "join_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can also alias the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>qcstate</th>\n",
       "      <th>roi_id</th>\n",
       "      <th>st1r</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>samj</td>\n",
       "      <td>manual_passed</td>\n",
       "      <td>562630185</td>\n",
       "      <td>525757437</td>\n",
       "      <td>2017-01-06 09:07:31</td>\n",
       "      <td>525757437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>samj</td>\n",
       "      <td>manual_failed</td>\n",
       "      <td>562438408</td>\n",
       "      <td>525757437</td>\n",
       "      <td>2017-01-04 15:42:32</td>\n",
       "      <td>525757437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>samj</td>\n",
       "      <td>manual_passed</td>\n",
       "      <td>562540356</td>\n",
       "      <td>525757437</td>\n",
       "      <td>2017-01-05 14:39:22</td>\n",
       "      <td>525757437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>samj</td>\n",
       "      <td>manual_passed</td>\n",
       "      <td>562534360</td>\n",
       "      <td>525757437</td>\n",
       "      <td>2017-01-05 13:28:19</td>\n",
       "      <td>525757437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>samj</td>\n",
       "      <td>manual_passed</td>\n",
       "      <td>562381380</td>\n",
       "      <td>525757437</td>\n",
       "      <td>2017-01-04 10:17:49</td>\n",
       "      <td>525757437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    username        qcstate     roi_id       st1r                date  \\\n",
       "705     samj  manual_passed  562630185  525757437 2017-01-06 09:07:31   \n",
       "706     samj  manual_failed  562438408  525757437 2017-01-04 15:42:32   \n",
       "707     samj  manual_passed  562540356  525757437 2017-01-05 14:39:22   \n",
       "708     samj  manual_passed  562534360  525757437 2017-01-05 13:28:19   \n",
       "709     samj  manual_passed  562381380  525757437 2017-01-04 10:17:49   \n",
       "\n",
       "            id  \n",
       "705  525757437  \n",
       "706  525757437  \n",
       "707  525757437  \n",
       "708  525757437  \n",
       "709  525757437  "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_query = \"SELECT err.id AS roi_id, err.recording_date AS date, err.stage1_reviewer_id AS st1r, \\\n",
    "err.workflow_state AS qcstate, users.id, users.login AS username \\\n",
    "FROM ephys_roi_results err \\\n",
    "JOIN users ON err.stage1_reviewer_id = users.id \\\n",
    "WHERE recording_date > '2017-01-01'\"\n",
    "join_df = get_lims_dataframe(join_query)\n",
    "join_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OK, this is great, but those roi_ids are so unsatisfying. Wouldn't it be awesome if we could actually recover the names of those specimens? Let's jump back to our original task.The weird thing here is that we're joining one column of the specimens table on another column of the specimens table. I've aliased each 'instance' of the specimens table as cell or slice, so hopefully this makes sense. Finally we can join the result on the ephys roi results table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>qcstate</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>roi_id</th>\n",
       "      <th>cell_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-05 11:07:44</td>\n",
       "      <td>manual_passed</td>\n",
       "      <td>318331264</td>\n",
       "      <td>318331262</td>\n",
       "      <td>Pvalb-IRES-Cre;Ai14-169125.02.02.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-05 11:12:00</td>\n",
       "      <td>manual_passed</td>\n",
       "      <td>318331342</td>\n",
       "      <td>318331340</td>\n",
       "      <td>Pvalb-IRES-Cre;Ai14-169125.03.01.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-05 11:33:20</td>\n",
       "      <td>auto_passed</td>\n",
       "      <td>318331484</td>\n",
       "      <td>318331482</td>\n",
       "      <td>Pvalb-IRES-Cre;Ai14-169125.03.02.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-05 13:15:44</td>\n",
       "      <td>auto_failed</td>\n",
       "      <td>318346915</td>\n",
       "      <td>318346913</td>\n",
       "      <td>Pvalb-IRES-Cre;Ai14-169125.04.02.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-05 13:49:52</td>\n",
       "      <td>auto_passed</td>\n",
       "      <td>318354031</td>\n",
       "      <td>318354029</td>\n",
       "      <td>Pvalb-IRES-Cre;Ai14-169128.03.02.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date        qcstate    cell_id     roi_id  \\\n",
       "0 2015-01-05 11:07:44  manual_passed  318331264  318331262   \n",
       "1 2015-01-05 11:12:00  manual_passed  318331342  318331340   \n",
       "2 2015-01-05 11:33:20    auto_passed  318331484  318331482   \n",
       "3 2015-01-05 13:15:44    auto_failed  318346915  318346913   \n",
       "4 2015-01-05 13:49:52    auto_passed  318354031  318354029   \n",
       "\n",
       "                             cell_name  \n",
       "0  Pvalb-IRES-Cre;Ai14-169125.02.02.01  \n",
       "1  Pvalb-IRES-Cre;Ai14-169125.03.01.01  \n",
       "2  Pvalb-IRES-Cre;Ai14-169125.03.02.01  \n",
       "3  Pvalb-IRES-Cre;Ai14-169125.04.02.01  \n",
       "4  Pvalb-IRES-Cre;Ai14-169128.03.02.01  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_query = \"SELECT cell.id AS cell_id, cell.name AS cell_name, err.id AS roi_id, err.recording_date AS date, \\\n",
    "err.workflow_state as qcstate \\\n",
    "FROM specimens cell \\\n",
    "JOIN specimens slice ON cell.parent_id = slice.id \\\n",
    "JOIN ephys_roi_results err ON err.id = cell.ephys_roi_result_id \\\n",
    "WHERE err.recording_date > '2015-01-01'\"\n",
    "cell_df = get_lims_dataframe(cell_query)\n",
    "cell_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Now can you put all this together, and figure out which cell names you were a stage 1 reviewer for...?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That concludes this little notebook. I hope it was useful. If you want to learn/practice more SQL syntax without the context of the Python wrapper for our PostgreSQL LIMS database, I recommend the following resources:\n",
    "https://www.w3schools.com/sql/\n",
    "https://community.modeanalytics.com/sql/tutorial/introduction-to-sql/"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
